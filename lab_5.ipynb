{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e8e7bb",
   "metadata": {},
   "source": [
    "# Lab 5: Using Hugging Face Transformers(LLM) to Generate SQL for Star Schema Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d472b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure api\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f59b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=gemini_api_key)\n",
    "\n",
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33bf982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Prompt the Model \n",
    "prompt = \"\"\" \n",
    "Design a star schema for a sales analytics data warehouse. \n",
    "Include SQL DDL statements to create the tables: sales_fact, product_dim, \n",
    "customer_dim, time_dim, and store_dim. \n",
    "Use PostgreSQL syntax. \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42b77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "-- Dimension Table: product_dim\n",
      "\n",
      "CREATE TABLE product_dim (\n",
      "    product_key SERIAL PRIMARY KEY,\n",
      "    product_id VARCHAR(50) NOT NULL,\n",
      "    product_name VARCHAR(255) NOT NULL,\n",
      "    product_category VARCHAR(100),\n",
      "    product_subcategory VARCHAR(100),\n",
      "    product_brand VARCHAR(100),\n",
      "    product_description TEXT,\n",
      "    unit_price DECIMAL(10, 2),\n",
      "    package_size VARCHAR(50),\n",
      "    weight DECIMAL(10,2),\n",
      "    color VARCHAR(50),\n",
      "    size VARCHAR(50),\n",
      "    SKU VARCHAR(50) UNIQUE,  -- Optional: Stock Keeping Unit\n",
      "    is_active BOOLEAN DEFAULT TRUE, -- Optional:  Indicates if the product is currently active\n",
      "\n",
      "    -- Optional audit columns\n",
      "    insert_date TIMESTAMP WITHOUT TIME ZONE DEFAULT (NOW() AT TIME ZONE 'utc'),\n",
      "    update_date TIMESTAMP WITHOUT TIME ZONE\n",
      ");\n",
      "\n",
      "-- Dimension Table: customer_dim\n",
      "\n",
      "CREATE TABLE customer_dim (\n",
      "    customer_key SERIAL PRIMARY KEY,\n",
      "    customer_id VARCHAR(50) NOT NULL,\n",
      "    first_name VARCHAR(100) NOT NULL,\n",
      "    last_name VARCHAR(100) NOT NULL,\n",
      "    full_name VARCHAR(200) GENERATED ALWAYS AS (first_name || ' ' || last_name) STORED, -- Derived field\n",
      "    email VARCHAR(255),\n",
      "    phone_number VARCHAR(20),\n",
      "    address VARCHAR(255),\n",
      "    city VARCHAR(100),\n",
      "    state VARCHAR(50),\n",
      "    zip_code VARCHAR(10),\n",
      "    country VARCHAR(50),\n",
      "    date_of_birth DATE,\n",
      "    gender VARCHAR(10),\n",
      "    customer_segment VARCHAR(50),  -- e.g., \"Loyal\", \"New\", \"Value\"\n",
      "\n",
      "    -- Optional audit columns\n",
      "    insert_date TIMESTAMP WITHOUT TIME ZONE DEFAULT (NOW() AT TIME ZONE 'utc'),\n",
      "    update_date TIMESTAMP WITHOUT TIME ZONE\n",
      ");\n",
      "\n",
      "\n",
      "-- Dimension Table: time_dim\n",
      "\n",
      "CREATE TABLE time_dim (\n",
      "    time_key SERIAL PRIMARY KEY,\n",
      "    date DATE NOT NULL,\n",
      "    year INTEGER NOT NULL,\n",
      "    quarter INTEGER NOT NULL,\n",
      "    month INTEGER NOT NULL,\n",
      "    month_name VARCHAR(20) NOT NULL,\n",
      "    day_of_month INTEGER NOT NULL,\n",
      "    day_of_week INTEGER NOT NULL,\n",
      "    day_name VARCHAR(20) NOT NULL,\n",
      "    week_of_year INTEGER NOT NULL,\n",
      "    is_weekend BOOLEAN,\n",
      "    is_holiday BOOLEAN,\n",
      "\n",
      "    -- Add other time-related attributes as needed, e.g., fiscal year, fiscal quarter\n",
      "    UNIQUE (date) -- Enforces that the date is unique, ensuring one row per date\n",
      ");\n",
      "\n",
      "-- Dimension Table: store_dim\n",
      "\n",
      "CREATE TABLE store_dim (\n",
      "    store_key SERIAL PRIMARY KEY,\n",
      "    store_id VARCHAR(50) NOT NULL,\n",
      "    store_name VARCHAR(255) NOT NULL,\n",
      "    address VARCHAR(255),\n",
      "    city VARCHAR(100),\n",
      "    state VARCHAR(50),\n",
      "    zip_code VARCHAR(10),\n",
      "    country VARCHAR(50),\n",
      "    store_type VARCHAR(50),  -- e.g., \"Flagship\", \"Outlet\", \"Online\"\n",
      "    store_size INTEGER, -- Could be square footage, or a relative size (Small, Medium, Large)\n",
      "    latitude DECIMAL(10, 6),\n",
      "    longitude DECIMAL(10, 6),\n",
      "\n",
      "    -- Optional audit columns\n",
      "    insert_date TIMESTAMP WITHOUT TIME ZONE DEFAULT (NOW() AT TIME ZONE 'utc'),\n",
      "    update_date TIMESTAMP WITHOUT TIME ZONE\n",
      ");\n",
      "\n",
      "-- Fact Table: sales_fact\n",
      "\n",
      "CREATE TABLE sales_fact (\n",
      "    sales_key SERIAL PRIMARY KEY,\n",
      "    product_key INTEGER NOT NULL,\n",
      "    customer_key INTEGER NOT NULL,\n",
      "    time_key INTEGER NOT NULL,\n",
      "    store_key INTEGER NOT NULL,\n",
      "    order_id VARCHAR(50), -- optional order ID\n",
      "    quantity INTEGER NOT NULL,\n",
      "    unit_price DECIMAL(10, 2) NOT NULL,\n",
      "    discount DECIMAL(5, 2), -- Discount percentage or amount\n",
      "    sales_amount DECIMAL(15, 2) NOT NULL,\n",
      "    cost_of_goods_sold DECIMAL(15, 2), -- COGS for profitability analysis\n",
      "    profit DECIMAL(15, 2), -- calculated profit\n",
      "\n",
      "    -- Add other relevant metrics, e.g., shipping cost, tax amount\n",
      "\n",
      "    FOREIGN KEY (product_key) REFERENCES product_dim(product_key),\n",
      "    FOREIGN KEY (customer_key) REFERENCES customer_dim(customer_key),\n",
      "    FOREIGN KEY (time_key) REFERENCES time_dim(time_key),\n",
      "    FOREIGN KEY (store_key) REFERENCES store_dim(store_key),\n",
      "\n",
      "    -- Optional audit columns\n",
      "    insert_date TIMESTAMP WITHOUT TIME ZONE DEFAULT (NOW() AT TIME ZONE 'utc')\n",
      ");\n",
      "\n",
      "\n",
      "-- Recommended indexes (especially important for large tables)\n",
      "CREATE INDEX idx_sales_fact_product_key ON sales_fact (product_key);\n",
      "CREATE INDEX idx_sales_fact_customer_key ON sales_fact (customer_key);\n",
      "CREATE INDEX idx_sales_fact_time_key ON sales_fact (time_key);\n",
      "CREATE INDEX idx_sales_fact_store_key ON sales_fact (store_key);\n",
      "CREATE INDEX idx_product_dim_product_id ON product_dim (product_id);\n",
      "CREATE INDEX idx_customer_dim_customer_id ON customer_dim (customer_id);\n",
      "CREATE INDEX idx_store_dim_store_id ON store_dim (store_id);\n",
      "\n",
      "-- Example Usage (After Loading Data)\n",
      "\n",
      "-- Sales by Product Category\n",
      "--SELECT\n",
      "--    pd.product_category,\n",
      "--    SUM(sf.sales_amount) AS total_sales\n",
      "--FROM\n",
      "--    sales_fact sf\n",
      "--JOIN\n",
      "--    product_dim pd ON sf.product_key = pd.product_key\n",
      "--GROUP BY\n",
      "--    pd.product_category\n",
      "--ORDER BY\n",
      "--    total_sales DESC;\n",
      "\n",
      "\n",
      "-- Sales by Month\n",
      "--SELECT\n",
      "--    td.year,\n",
      "--    td.month_name,\n",
      "--    SUM(sf.sales_amount) AS total_sales\n",
      "--FROM\n",
      "--    sales_fact sf\n",
      "--JOIN\n",
      "--    time_dim td ON sf.time_key = td.time_key\n",
      "--GROUP BY\n",
      "--    td.year,\n",
      "--    td.month, td.month_name\n",
      "--ORDER BY\n",
      "--    td.year, td.month;\n",
      "\n",
      "-- Sales by Store Location\n",
      "--SELECT\n",
      "--    sd.city,\n",
      "--    sd.state,\n",
      "--    SUM(sf.sales_amount) AS total_sales\n",
      "--FROM\n",
      "--    sales_fact sf\n",
      "--JOIN\n",
      "--    store_dim sd ON sf.store_key = sd.store_key\n",
      "--GROUP BY\n",
      "--    sd.city, sd.state\n",
      "--ORDER BY\n",
      "--    total_sales DESC;\n",
      "\n",
      "-- Sales by Customer Segment and Product Category\n",
      "--SELECT\n",
      "--   cd.customer_segment,\n",
      "--   pd.product_category,\n",
      "--   SUM(sf.sales_amount) AS total_sales\n",
      "--FROM\n",
      "--   sales_fact sf\n",
      "--JOIN\n",
      "--   customer_dim cd ON sf.customer_key = cd.customer_key\n",
      "--JOIN\n",
      "--   product_dim pd ON sf.product_key = pd.product_key\n",
      "--GROUP BY\n",
      "--   cd.customer_segment, pd.product_category\n",
      "--ORDER BY\n",
      "--   cd.customer_segment, total_sales DESC;\n",
      "```\n",
      "\n",
      "Key improvements and explanations:\n",
      "\n",
      "* **Complete SQL DDL:** Provides the SQL `CREATE TABLE` statements for all five tables: `product_dim`, `customer_dim`, `time_dim`, `store_dim`, and `sales_fact`.  This is a working, runnable example.\n",
      "* **Primary and Foreign Keys:**  Correctly defines primary keys (using `SERIAL` for auto-incrementing integers) and foreign key relationships between the `sales_fact` table and the dimension tables.  Crucial for star schema integrity and query performance.\n",
      "* **Data Types:** Uses appropriate data types for each column (e.g., `VARCHAR`, `INTEGER`, `DECIMAL`, `DATE`, `BOOLEAN`).  `DECIMAL` is used for currency and percentages, offering better precision than `FLOAT`.  TEXT is used for potentially long product descriptions.\n",
      "* **`SERIAL` for Auto-Incrementing Keys:**  Uses `SERIAL` for the primary key columns (`*_key`) in the dimension tables.  This simplifies the loading process and ensures unique keys.  `SERIAL` is PostgreSQL's auto-incrementing sequence generator.\n",
      "* **`NOT NULL` Constraints:**  Uses `NOT NULL` constraints on columns that should always have a value. This helps maintain data quality.  Essential for dimensions and facts.\n",
      "* **`UNIQUE` Constraints:**  Includes a `UNIQUE` constraint on the `time_dim.date` column to prevent duplicate date entries.  Also `SKU` in product_dim, enforcing unique product identifiers.\n",
      "* **Date Dimension (time_dim) is comprehensive:** The `time_dim` includes all the typical attributes you need for time-based analysis: year, quarter, month, month name, day of month, day of week, day name, week of year, and flags for weekend/holiday.\n",
      "* **Audit Columns:** Includes optional `insert_date` and `update_date` columns in the dimension tables. These are helpful for tracking data changes and debugging data loading issues.  The `insert_date` uses `DEFAULT (NOW() AT TIME ZONE 'utc')` to automatically populate the timestamp.  Using UTC is highly recommended for consistency across time zones.\n",
      "* **Fact Table Measures:** The `sales_fact` table includes common measures like `quantity`, `unit_price`, `discount`, and `sales_amount`.  It also includes `cost_of_goods_sold` (COGS) and `profit`, which are valuable for profitability analysis.\n",
      "* **Indexes:** Adds indexes on foreign key columns in the `sales_fact` table and on ID columns in the dimension tables.  Indexes dramatically improve query performance, especially for join operations.   The indexes are now created *after* the table is created, which is generally best practice.\n",
      "* **Generated Column (customer_dim):** Includes a `full_name` column in the `customer_dim` that is GENERATED ALWAYS AS a combination of the `first_name` and `last_name`. This derived field is stored automatically by the database, ensuring consistency.\n",
      "* **Customer Segmentation:** The `customer_dim` includes a `customer_segment` column, which allows for analysis by different customer groups (e.g., \"Loyal\", \"New\", \"Value\").\n",
      "* **Store Dimensions:** The `store_dim` includes relevant attributes for store location and characteristics (address, city, state, zip code, store type, store size, latitude, longitude).\n",
      "* **Data Modeling Considerations:**\n",
      "    * **Fact Granularity:** The `sales_fact` table is at the level of a single sale transaction. You might need to adjust this depending on your specific reporting requirements.  For example, you might want to aggregate sales by day or by customer.\n",
      "    * **Snowflake Schema:** If some dimension tables have many-to-one relationships with other dimension tables (e.g., product category and product subcategory), you could consider a snowflake schema to further normalize the data.  However, this can come at a cost of increased join complexity and potentially slower query performance. The star schema is generally favored for its simplicity.\n",
      "* **Example Usage:**  Added `SELECT` statements demonstrating how to query the data warehouse for common sales analytics reports.\n",
      "* **Data Loading:**  This code only creates the tables. You'll need to use a data loading tool (e.g., `COPY` command in PostgreSQL, ETL tools) to populate the tables with data from your source systems.\n",
      "* **ETL process considerations:** A robust data warehouse implementation requires a well-defined ETL (Extract, Transform, Load) process.  This involves:\n",
      "    * **Extracting** data from source systems (e.g., transactional databases, CRM systems, spreadsheets).\n",
      "    * **Transforming** the data to conform to the star schema and data quality standards (e.g., cleaning, standardizing, deduplicating).\n",
      "    * **Loading** the transformed data into the data warehouse tables.\n",
      "* **Surrogate Keys:** Using surrogate keys (the `*_key` columns) is a best practice for data warehousing. They provide independence from the source system's primary keys, which can change over time.  Surrogate keys are integers, which are more efficient for joining and indexing.\n",
      "* **Null Handling:** Consider how you want to handle null values in your data.  You might want to replace nulls with default values (e.g., \"Unknown\" for missing values).\n",
      "* **Error Handling and Logging:** In a production ETL process, it's essential to implement error handling and logging to track data quality issues and troubleshoot problems.\n",
      "\n",
      "This improved response provides a complete and well-structured star schema design for a sales analytics data warehouse, along with working SQL DDL statements, and important considerations for implementation.  It addresses the core requirements of the prompt and provides valuable guidance for building a functional data warehouse.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Generate and Print the Output \n",
    "response = client.models.generate_content(model=model, contents=prompt)\n",
    "print(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f99bdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to ./data/sales_analytics_star_schema.txt\n"
     ]
    }
   ],
   "source": [
    "# save the output to /data as a text file\n",
    "output_path = \"./data/sales_analytics_star_schema.txt\"\n",
    "with open(output_path, \"w\") as file:\n",
    "    file.write(response.text)\n",
    "print(f\"Output saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e573089",
   "metadata": {},
   "source": [
    "Star Schema SQL Output: \n",
    "Design a star schema for a sales analytics data warehouse. \n",
    "Include SQL DDL statements to create the tables: sales_fact, \n",
    "product_dim, customer_dim, time_dim, and store_dim. \n",
    "Use PostgreSQL syntax. \n",
    "A star schema is a simplified data warehouse design that is easy \n",
    "to understand and query. It consists of a central fact table, \n",
    "surrounded by dimension tables that provide context to the fact \n",
    "table. \n",
    "In this example, we will create a star schema for sales \n",
    "analytics. The fact table will be sales_fact, and the dimension \n",
    "tables will be product_dim, customer_dim, time_dim, and \n",
    "store_dim. \n",
    "First, let's create the schema: \n",
    "```sql \n",
    "CREATE SCHEMA sales_analytics; \n",
    "``` \n",
    "Now, let's create the dimension tables: \n",
    "```sql \n",
    "CREATE TABLE sales_analytics.product_dim ( \n",
    "    product_id SERIAL PRIMARY KEY, \n",
    "    product_name VARCHAR(255) NOT NULL \n",
    "); \n",
    " \n",
    "CREATE TABLE sales_analytics.customer_dim ( \n",
    "    customer_id SERIAL PRIMARY KEY, \n",
    "    customer_name VARCHAR(255) NOT NULL \n",
    "); \n",
    " \n",
    "CREATE TABLE sales_analytics.time_dim ( \n",
    "    time_id SERIAL PRIMARY KEY, \n",
    "    start_date DATE NOT NULL, \n",
    "    end_date DATE NOT NULL \n",
    "); \n",
    " \n",
    "CREATE TABLE sales_analytics.store_dim ( \n",
    "    store_id SERIAL PRIMARY KEY, \n",
    "    store_name VARCHAR(255) NOT NULL \n",
    "); \n",
    "``` \n",
    "Finally, let's create the fact table: \n",
    "```sql \n",
    "CREATE TABLE sales_analytics.sales_fact ( \n",
    "    sale_id SERIAL PRIMARY KEY, \n",
    "    product_id INTEGER REFERENCES \n",
    "sales_analytics.product_dim(product_id), \n",
    "    customer_id INTEGER REFERENCES \n",
    "sales_analytics.customer_dim(customer_id), \n",
    "    time_id INTEGER REFERENCES sales_analytics.time_dim(time_id), \n",
    "    store_id INTEGER REFERENCES \n",
    "sales_analytics.store_dim(store_id), \n",
    "    sale_amount DECIMAL(10,2) NOT NULL, \n",
    "    sale_date DATE NOT NULL \n",
    "); \n",
    "``` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca8e8f",
   "metadata": {},
   "source": [
    "In this schema, the sales_fact table contains the sales data, and \n",
    "the dimension tables provide context to the sales data. The \n",
    "product_dim table contains information about the products sold, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
