{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "741220a1",
   "metadata": {},
   "source": [
    "# Lab 8: Instruction-Based Data Generation and Classification Using Mistral-7B and Decision Trees\n",
    "\n",
    "## Step 1: Launch a Colab Notebook and Set Up Environment Install necessary packages first: \n",
    "```bash\n",
    "!pip install torch torchvision torchaudio transformers accelerate bitsandbytes \n",
    "huggingface_hub scikit-learn pandas numpy matplotlib â€“quiet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea7fef",
   "metadata": {},
   "source": [
    "## Step 2: Load and Run Mistral Model from Hugging Face \n",
    "You can directly load Mistral-7B-Instruct-v0.1 from Hugging Face. This model supports instruction-based prompting similar to GPT-based models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231dfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from huggingface_hub import login \n",
    "\n",
    "# Replace \"your_token_here\" with your actual Hugging Face access token \n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"your_token_here\"  \n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5335ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, \n",
    "BitsAndBytesConfig, pipeline \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\" \n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True) \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "token=os.environ[\"HUGGINGFACE_TOKEN\"]) \n",
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "model_name, \n",
    "quantization_config=quant_config, \n",
    "device_map=\"auto\", \n",
    "token=os.environ[\"HUGGINGFACE_TOKEN\"] \n",
    ") \n",
    "text_gen_pipeline = pipeline( \n",
    "\"text-generation\", \n",
    "model=model, \n",
    "tokenizer=tokenizer, \n",
    "device_map=\"auto\" \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4b666",
   "metadata": {},
   "source": [
    "## Step 3: Run a Basic Prompt \n",
    "Here's an example to demonstrate how Mistral responds to instructions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" \n",
    "Generate ONLY CSV data without any explanation. It should contain exactly 30 \n",
    "rows with the columns: age, income, decision (yes/no).  \n",
    "Ensure that: - age values are between 18 and 65, - income ranges from 30000 to 150000, - decision has a roughly equal number of 'yes' and 'no'. \n",
    "\"\"\" \n",
    "# Increased max_new_tokens for complete CSV generation \n",
    "response = text_gen_pipeline(prompt, max_new_tokens=800) \n",
    "generated_csv = response[0]['generated_text'].strip() \n",
    "print(\"Generated CSV:\\n\", generated_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b3c4d",
   "metadata": {},
   "source": [
    "## Step 4: Continue with Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087927bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db446eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume response is the output from text_gen_pipeline \n",
    "response_text = response[0]['generated_text'] \n",
    " \n",
    "# Split the response text into lines and then into data points \n",
    "data_points = [] \n",
    "for line in response_text.strip().split('\\n'): \n",
    "    if line: \n",
    "        try: \n",
    "            age, income, purchase = line.split(',') \n",
    "            data_points.append([int(age), int(income), purchase.strip()]) \n",
    "        except ValueError: \n",
    "            # Handle lines that don't conform to the expected format \n",
    "            print(f\"Skipping line: {line}\") \n",
    " \n",
    "# Create a pandas DataFrame \n",
    "df = pd.DataFrame(data_points, columns=['age', 'income', 'purchase']) \n",
    " \n",
    "# Convert 'purchase' to numerical (0 for 'no', 1 for 'yes') \n",
    "df['purchase'] = df['purchase'].map({'no': 0, 'yes': 1}) \n",
    "# Define X and y \n",
    "X = df[['age', 'income']] \n",
    "y = df['purchase']\n",
    "\n",
    "# Now you can use train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "model = DecisionTreeClassifier(max_depth=5) \n",
    "model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier, export_text \n",
    "from sklearn.metrics import classification_report \n",
    "# Decision rules visualization \n",
    "rules = export_text(model, feature_names=['age', 'income']) \n",
    "print(\"Decision Tree Rules:\\n\", rules) \n",
    "# Evaluate model clearly \n",
    "predictions = model.predict(X_test) \n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
